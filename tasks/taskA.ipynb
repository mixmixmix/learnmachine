{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Task A\n",
    "\n",
    "*M Kundegorski*, Fjelltopp Ltd, University of Glasgow, 2019-2020\n",
    "\n",
    "\n",
    "In this task you will read in some toy data from an experiment and, using linear regression, try to predict the outcome for an 'unseen' or unknown measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify how matplotlib interacts with jupyter display. This is not a Python command but Jupyter's\n",
    "%matplotlib inline \n",
    "\n",
    "#Import useful libraries\n",
    "import matplotlib.pyplot as plt  # We will use matplotlib for plotting\n",
    "import pandas as pd  # We will use pandas DataFrames for storing features\n",
    "import numpy as np  # We will use NumPy arrays to store image data\n",
    "\n",
    "# Utils is a custom module written to simplify these tutorials\n",
    "# You do not need to understand these codes for this practical\n",
    "from utils.practice_data import generateNiceData\n",
    "\n",
    "# Generate a pandas Dataframe `problem` with some toy results\n",
    "# Each row, a data point, has four features: A, B, C, Y\n",
    "# These could, for example, be length, intensity, etc.\n",
    "number_of_samples=100\n",
    "number_of_features=3\n",
    "problem = generateNiceData(number_of_features,number_of_samples,noNoise=True) \n",
    "problem.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can show the top of the pandas dataframe using .head(N) method\n",
    "problem.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or you can display some sample data points using .sample(N) method\n",
    "problem.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can modify the plotting function below to see the relationship between each variable A, B and C, and output Y. \n",
    "#Does the relationship look like it is linear?\n",
    "plt.plot(problem['A'],problem['Y'], marker='o', linewidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task\n",
    "\n",
    "In one experiment we were able to measure three features: A, B, C which we suspect allow for prediction of some other feature Y. With enough *training data* containing both input features A, B, C and additionally measured output Y, we can learn a model to predict Y.\n",
    "\n",
    "Given these three features (A, B and C) we want to predict the value of feature Y.\n",
    "\n",
    "1. Let's start with a multivariate linear regression (assuming the relationship between our variables is simple).\n",
    "2. Advanced: Following see how the performance changes with and without noise in data\n",
    "3. Advanced: See how performance changes depending on size of the problem\n",
    "4. Advanced: Then try to provide non-linear features (i.e. assuming the relationship between our variables is complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from pandas series needs to be converted to familiar numpy arrays\n",
    "x = problem.loc[:,['A','B','C']].values\n",
    "y = problem.loc[:,'Y'].values\n",
    "\n",
    "print(x.shape, y.shape)  # check our array shapes make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A.1 \n",
    "\n",
    "Read the documentation for function [sklearn.model_selection.train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), start with the second example provided.\n",
    "\n",
    "In the cell below, complete the function call (by replacing all the `____`s) to split our dataset into 80% `x_train`/`y_train` (training) and 20% `x_test`/`y_test` (testing) subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection  # for trans_test_split function\n",
    "\n",
    "____, ____, ____, ____  = model_selection.train_test_split(____, ____, test_size=____, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A.2\n",
    "\n",
    " Look at the [Linear Regression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) documentation and examples. In the code below, we have initialised a Linear Regression model. Add the following lines of code:\n",
    "1. A line that 'fit's a model to our training data,\n",
    "2. A line that 'predict's the value of Y for our test data.\n",
    "\n",
    "What do the intercept and slope represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model  # this submodule contains the 'LinearRegression' function\n",
    "\n",
    "mv_regression = linear_model.LinearRegression(normalize=True) #How would it perform without normalisation?\n",
    "\n",
    "# Fit regression model to feature data x_train and target y_train\n",
    "# ADD CODE HERE:\n",
    "\n",
    "# Fill vector y_predict with estimations of target y_predict from data x_test\n",
    "# ADD CODE HERE:\n",
    "\n",
    "print(\"Intercept {}\".format(mv_regression.intercept_))\n",
    "print(\"Slope {}\".format(mv_regression.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we want to get an idea of how well our models fits our data (by comparing out prediction to our known testing data values), there are a variety of error metrics that can be used for this. Run the cell below to compare the 'True' or known values and the predicted values as well as three common error metrics. How do you interpret these numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict))  )\n",
    "print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)) )\n",
    "print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers are all well and good, but often it's easier to understand our results when plotted visually. Run the cell below to compare the true and predicted values for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "axis.plot(y_test, y_test, '--')  # plot true vs true, i.e. the ideal case\n",
    "axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "axis.set_ylabel('Predicted Value')\n",
    "axis.set_xlabel('True Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.3\n",
    "\n",
    "In the cell below we have put all this code into a loop. Using `np.arange` we have defined a range of sample sizes. Run the loop to see how sample size affects the results.\n",
    "\n",
    "So far, these experiments have been magically noise free. Make `noNoise=False` in the call to function generateNiceData() in the first cell and re-run it. How does noise affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the error metrics for each sample size\n",
    "errors = pd.DataFrame(index=np.arange(20, 200, 20),columns=['MAE', 'MSE', 'RMS'])\n",
    "\n",
    "for number_of_samples in np.arange(20, 200, 20):\n",
    "    print('Running for {0} samples...'.format(number_of_samples))\n",
    "    problem = generateNiceData(3,number_of_samples,noNoise=True) # CHANGE THIS LINE\n",
    "    \n",
    "    #Data from pandas series needs to be converted to familiar numpy arrays\n",
    "    x = problem.loc[:,['A','B','C']].values\n",
    "    y = problem.loc[:,'Y'].values\n",
    "    \n",
    "    # Split test/train data\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Initialise Linear Regression Model\n",
    "    mv_regression = linear_model.LinearRegression(normalize=True) #How would it perform without normalisation?\n",
    "    \n",
    "    # Fit regression model to feature data x_train and target y_train\n",
    "    mv_regression.fit(x_train,y_train)\n",
    "    \n",
    "    # Fill vector y_predict with estimations of target y_predict from data x_test\n",
    "    y_predict = mv_regression.predict(x_test)\n",
    "    \n",
    "    # Print Fit\n",
    "    print(\"Intercept {}\".format(mv_regression.intercept_))\n",
    "    print(\"Slope {}\".format(mv_regression.coef_))\n",
    "    \n",
    "    # Print Error Metrics\n",
    "    results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "    print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict)))\n",
    "    errors.loc[number_of_samples,'MAE'] = metrics.mean_absolute_error(y_test, y_predict)\n",
    "    print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)))\n",
    "    errors.loc[number_of_samples,'MSE'] = metrics.mean_squared_error(y_test, y_predict)\n",
    "    print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))\n",
    "    errors.loc[number_of_samples,'RMS'] = np.sqrt(metrics.mean_squared_error(y_test, y_predict))\n",
    "    \n",
    "    # Plot\n",
    "    f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "    axis.plot(y_test, y_test, '-')  # plot true vs true, i.e. the ideal case\n",
    "    axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "    axis.set_ylabel('Predicted Value')\n",
    "    axis.set_xlabel('True Value')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# Show errors and create a quick plot\n",
    "display(errors)\n",
    "\n",
    "fErr, axErr = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "errors.plot(ax=axErr)\n",
    "axErr.set_ylabel('Error Value')\n",
    "axErr.set_xlabel('Sample Size')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.4\n",
    "\n",
    "Given your extensive knowledge of the property Y, you suspect that measurement B and C have a non-linear relation to Y. \n",
    "\n",
    "Modify the following cell to use function [np.power()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.power.html) and [np.sin()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html?highlight=sin#numpy.sin) to create additional non-linear features z_b and z_c. \n",
    "\n",
    "*Hint:* try different powers of `x_b`, from 2 to 8 to see when the fit is the closest. \n",
    "\n",
    "*Hint:* Apply sine function firectly to `x_c: z_c = np.sin(x_c)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = problem.loc[:,['A']].values\n",
    "x_b = problem.loc[:,['B']].values\n",
    "x_c = problem.loc[:,['C']].values\n",
    "\n",
    "#Here we create *new features*. Change them to be a power and sin of existing features\n",
    "z_b = x_b\n",
    "z_c = x_c \n",
    "\n",
    "#You can either add z-features to your existing measurements, or replace x_b and x_c with the non-linear features.\n",
    "x=np.concatenate((x_a,x_b,x_c,z_b,z_c),axis=1)\n",
    "x=np.concatenate((x_a,z_b,z_c),axis=1)\n",
    "#comment out one of the above lines to see different results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.5\n",
    "\n",
    "Copy the code from the cells above (task A.2) to try linear regression with your non-linear features. Do you need to change anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.6\n",
    "\n",
    "Display the results on the test dataset by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict))  )\n",
    "print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)) )\n",
    "print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))\n",
    "\n",
    "f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "axis.plot(y_test, y_test, 'x')  # plot true vs true, i.e. the ideal case\n",
    "axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "axis.set_ylabel('Predicted Value')\n",
    "axis.set_xlabel('True Value')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
