{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Task E\n",
    "\n",
    "*M Kundegorski*, Fjelltopp Ltd., University of Glasgow, 2019-2020\n",
    "\n",
    "In this task you will use image information to cluster images into classes based on similarity of colour. In reality we could use any feature but colour is very visual and easy to follow.\n",
    "\n",
    "There are 6 'classes' (colours) of blob, each of them has different value of hue (but the same mean intensity).\n",
    "\n",
    "This task is based on a scikit-learn tutorial of k-means clustering: https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html#sphx-glr-auto-examples-cluster-plot-cluster-iris-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task\n",
    "\n",
    "In one experiment we were able to take a 'branbow'-esque dataset, i.e. every cell is expressing a combination of different fluorophores (colours), and each colour combination represents a type of cell. We imaged these cells with an RGB camera. These cells are sparse so we were easily able to segment them, find their bounding box and create a database of images each containing a single cell. We want to use clustering to automatically identify which cell belongs to which cell-type. Luckily, we've convinced a PhD student to manually label our sample database so we can confirm our results at the end.\n",
    "\n",
    "Given the colour of our cells we want to automatically, and in an unsupervised fashion, 'cluster' our cells into classes, ignoring other features like shape or size.\n",
    "\n",
    "1. Let's start by loading our data and visualising the manual class labels in RGB space (other colour spaces would also work)\n",
    "2. Use k-means clustering to cluster our data and compare it to our manual labels\n",
    "3. Advanced: Use sum of square errors to identify the correct 'k' to use\n",
    "4. Advanced: Use mean shift clustering to cluster our data and compare it to our manual labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E.1\n",
    "\n",
    "Let's start by loading data. Later on, you can change parameters to see how the clustering results change with different numbers and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Utils is a custom module written to simplify these tutorials\n",
    "# You do not need to understand these codes for this practical\n",
    "from utils.practice_data import generateBlobsData  # this loads data into a DataFrame\n",
    "from utils.practice_data import showBlobs  # this allows quick visualisation of the data\n",
    "\n",
    "imageDir = './assets/simple_blobs/'\n",
    "number_of_classes = 6\n",
    "# Is 30 a sufficent number of samples? How much noise can our algorithms deal with?\n",
    "number_of_samples = 30\n",
    "noise = 10 #value from 0 to 250\n",
    "problem = generateBlobsData(imageDir, number_of_classes, number_of_samples, imSize = 100, colour=True, noiseSize = noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "display(problem.loc[:,'class'].describe())  # describe classes\n",
    "showBlobs(problem.sample(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E.2\n",
    "\n",
    "Time for some data wrangling - as usual the data needs to have right datatype required by the algorithm. For this simple clustering example we're going to extract the mean 'red', the mean 'green' and the mean 'blue' value for each cell. To make things simply, given we've only got one cell per image, we will use the means for the whole image. How might this affect our means and therefore our clustering? Should we use the mean or the median?\n",
    "\n",
    "Run the following cell to get the median colour channel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=problem.loc[:,'class'].values.astype(int)  # Convert classes to int\n",
    "\n",
    "for cell in problem.index:\n",
    "    problem.loc[cell,'mean-R'] = problem.loc[cell,'raw_data'][:,:,0].mean()  # mean of the first (red) channel of our image data for this cell\n",
    "    problem.loc[cell,'mean-G'] = problem.loc[cell,'raw_data'][:,:,1].mean()  # mean of the second (green) channel of our image data for this cell\n",
    "    problem.loc[cell,'mean-B'] = problem.loc[cell,'raw_data'][:,:,2].mean()  # mean of the third (blue) channel of our image data for this cell\n",
    "\n",
    "problem.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to plot our cells on three axes - one for R, one for G and one for B. This code also colourcodes cells by their class (the manual class at the moment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axis = plt.subplots(1,1,subplot_kw={'projection':'3d'})  # create a figure with a single 3d axis (subplot)\n",
    "\n",
    "# Get a list of unique classes\n",
    "blob_classes = problem.loc[:,'class'].unique()\n",
    "\n",
    "# Plot each blob and label\n",
    "for blob_class in blob_classes:\n",
    "    axis.plot(problem[problem['class']==blob_class]['mean-R'],\n",
    "            problem[problem['class']==blob_class]['mean-G'],\n",
    "            problem[problem['class']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axis.set_ylabel('Red')\n",
    "axis.set_xlabel('Green')\n",
    "axis.set_zlabel('Blue')\n",
    "\n",
    "axis.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E.3\n",
    "\n",
    "Now you will use [sklearn.cluster.kMeans()](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) to perform k-means clustering on your data. This clustering algorithm never sees your manual class labels. Let's see if we can put your PhD student out of a job - I'm sure you have plenty more for them to do!\n",
    "\n",
    "Run the next cell to do this. How many clusters will you use (fill in the `____`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "# Initialise clustering algorithm\n",
    "k_means = cluster.KMeans(n_clusters=____)  # How would you decide how many clusters to choose?\n",
    "\n",
    "# Perform fit with colour data only (no class labels)\n",
    "k_means.fit(problem[['mean-R','mean-G','mean-B']])\n",
    "\n",
    "# Extract cluster labels\n",
    "problem['kMeans-cluster'] = k_means.labels_\n",
    "\n",
    "display(problem.describe())\n",
    "display(problem.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to plot your PhD student's clustering and the k-means clustering side-by-side. Note that the cluster *numbers* may not map exactly but the cluster *members* should be similar. Have any cells been wrongly classified? Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2,subplot_kw={'projection':'3d'})  # create a figure with two 3d axes (subplot)\n",
    "(axPhD, axKM) = ax.flatten()  # give each subplot a unique name\n",
    "\n",
    "# Get a list of unique PhD-student-derived classes\n",
    "phd_classes = problem.loc[:,'class'].unique()\n",
    "\n",
    "# Plot each blob and label\n",
    "for blob_class in phd_classes:\n",
    "    axPhD.plot(problem[problem['class']==blob_class]['mean-R'],\n",
    "            problem[problem['class']==blob_class]['mean-G'],\n",
    "            problem[problem['class']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axPhD.set_ylabel('Red')\n",
    "axPhD.set_xlabel('Green')\n",
    "axPhD.set_zlabel('Blue')\n",
    "\n",
    "axPhD.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "# Get a list of unique k-Means-derived classes\n",
    "km_classes = problem.loc[:,'kMeans-cluster'].unique()\n",
    "\n",
    "# Plot each blob and label\n",
    "for blob_class in km_classes:\n",
    "    axKM.plot(problem[problem['kMeans-cluster']==blob_class]['mean-R'],\n",
    "            problem[problem['kMeans-cluster']==blob_class]['mean-G'],\n",
    "            problem[problem['kMeans-cluster']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axKM.set_ylabel('Red')\n",
    "axKM.set_xlabel('Green')\n",
    "axKM.set_zlabel('Blue')\n",
    "\n",
    "axKM.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task E.4\n",
    "\n",
    "So far, we used our senses to guess that we needed 6 clusters. However, there is a relatively simple way to estimate the number of clusters we want from a k-means algorithm. First, we guess a reasonable range, for example, 1 to 10 clusters, and run k-means clustering for each guess. We then look for a 'knee' point in Sum of Square Errors (SSE) for each clustering. The SSE (or intertia) is the sum of distances from each sample (each cell) to the centre of it's cluster, e.g. the mean position of all cells in that cluster.\n",
    "\n",
    "You can access value of SSE using `.inertia_` attribute of a fitted k-means model.\n",
    "\n",
    "Use a for loop, and by copying the code above, create a cell to first the best 'k' to use for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task E.5\n",
    "\n",
    "K-means clustering is not the only unsupervised clustering algorithm. Check out [Mean Shift Clustering]().\n",
    "\n",
    "In a new cell, and using your k-means codes above, do mean shift clustering on this data. What happens when you change the bandwidth parameter?\n",
    "\n",
    "*Note:* Make sure you save your mean-shift clustering in a column of `problem` called `mean-shift-cluster`; this will make sure the plot cell below works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to plot the PhD, k-means and mean-shifted clustering side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,3,subplot_kw={'projection':'3d'})  # create a figure with three 3d axes (subplot)\n",
    "(axPhD, axKM, axMS) = ax.flatten()  # give each subplot a unique name\n",
    "\n",
    "# Get a list of unique PhD-student-derived classes\n",
    "phd_classes = problem.loc[:,'class'].unique()\n",
    "\n",
    "# Plot each blob and PhD-label\n",
    "for blob_class in phd_classes:\n",
    "    axPhD.plot(problem[problem['class']==blob_class]['mean-R'],\n",
    "            problem[problem['class']==blob_class]['mean-G'],\n",
    "            problem[problem['class']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axPhD.set_ylabel('Red')\n",
    "axPhD.set_xlabel('Green')\n",
    "axPhD.set_zlabel('Blue')\n",
    "\n",
    "axPhD.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "# Get a list of unique k-Means-derived classes\n",
    "km_classes = problem.loc[:,'kMeans-cluster'].unique()\n",
    "\n",
    "# Plot each blob and k-means cluster\n",
    "for blob_class in km_classes:\n",
    "    axKM.plot(problem[problem['kMeans-cluster']==blob_class]['mean-R'],\n",
    "            problem[problem['kMeans-cluster']==blob_class]['mean-G'],\n",
    "            problem[problem['kMeans-cluster']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axKM.set_ylabel('Red')\n",
    "axKM.set_xlabel('Green')\n",
    "axKM.set_zlabel('Blue')\n",
    "\n",
    "axKM.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "# Get a list of unique mean-shift-derived classes\n",
    "ms_classes = problem.loc[:,'mean-shift-cluster'].unique()\n",
    "\n",
    "# Plot each blob and mean-shift cluster\n",
    "for blob_class in ms_classes:\n",
    "    axMS.plot(problem[problem['mean-shift-cluster']==blob_class]['mean-R'],\n",
    "            problem[problem['mean-shift-cluster']==blob_class]['mean-G'],\n",
    "            problem[problem['mean-shift-cluster']==blob_class]['mean-B'], \n",
    "            'o', label=blob_class)\n",
    "axMS.set_ylabel('Red')\n",
    "axMS.set_xlabel('Green')\n",
    "axMS.set_zlabel('Blue')\n",
    "\n",
    "axMS.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))  # add a legend\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
